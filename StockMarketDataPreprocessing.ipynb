{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method name: Stock Market Data Preprocessing\n",
    "# purpose: This script pulls down daily data from a MongoDB instance, then processes to data for use in ML algos\n",
    "# created: 6/14/2020 12:01PM\n",
    "# Author: Zack Stinnett\n",
    "# Revisions: Added logging       6/14/2020 7:30PM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A big issue that was encountered is the indicators were developed using an older version that allowed ix and other \n",
    "# functions that are not longer supported, but the newest version of sklearn is required downstream\n",
    "# To run this, use an environment with older versions.\n",
    "# Analysis showed the stacking algorithm may not be useful, so changing environments is unnecessary.\n",
    "# Be sure to comment out the stacking algorithm lines in the next script if using an older environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import Functions.RetrieveIntradayData as ret\n",
    "import Functions.Indicators as ind\n",
    "from inspect import getmembers, isfunction\n",
    "import pymongo\n",
    "import concurrent.futures\n",
    "import datetime\n",
    "from sklearn.utils import resample\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='stockmarketdatapreprocessing.log', level=logging.INFO,\n",
    "                    format='%(levelname)s:%(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_client = pymongo.MongoClient('mongodb://mlcandidates:crackthecode@100.2.158.147:27017/')\n",
    "finDb = mongo_client['findata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dailyCollection = finDb['day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get data for all symbols\n",
    "all_stocks_daily_df = pd.DataFrame(list(dailyCollection.find({'close':{'$ne':'NaN'}})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of available stocks is 3928.\n"
     ]
    }
   ],
   "source": [
    "# Number of stock symbols\n",
    "print('The number of available stocks is {}.'.format(len(all_stocks_daily_df.Symbol.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next let's find out the number of null close prices\n",
    "# and try to choose stocks with lower null counts and non negative prices\n",
    "stock_null_percentages = {}\n",
    "stock_time_lengths = {}\n",
    "\n",
    "def get_close_null_percentage(symbol):\n",
    "    daily_df = pd.DataFrame(list(dailyCollection.find({'Symbol':symbol, 'close':{'$ne': 'NaN'}})))\n",
    "    stock_null_percentages[symbol] = daily_df['Close'].isnull().sum() / len(daily_df)\n",
    "    stock_time_lengths[symbol] = len(daily_df), len(daily_df[daily_df['Close']>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using multithreading to speed up data gathering\n",
    "symbols = all_stocks_daily_df.Symbol.unique()\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    executor.map(get_close_null_percentage, symbols)\n",
    "\n",
    "logging.info('Stock Data has been pulled in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_with_max_lengths = {k: v for k, v in stock_time_lengths.items() if (v[0]>75) and (v[1]>0)}\n",
    "stock_symbols_with_max_length_list = list(stocks_with_max_lengths.keys())\n",
    "null_percentage_with_max_len = {key: value for key, value in stock_null_percentages.items() if key in stock_symbols_with_max_length_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is a lot of nulls in this data, but most stocks only are missing 32% of the closes. \n",
    "# So let's get the top 100 stocks to analyze\n",
    "import operator\n",
    "top_stocks = sorted(null_percentage_with_max_len.items(), key=operator.itemgetter(1))[:100]\n",
    "stocks_to_analyze = [i[0] for i in top_stocks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am using cubic splines to fill in the nulls in due to their flexibility in fit complex data\n",
    "\n",
    "def create_interpolated_stock_df(symbol):\n",
    "    daily_df = pd.DataFrame(list(dailyCollection.find({'Symbol':symbol, 'close':{'$ne': 'NaN'}})))\n",
    "    daily_df.drop(['_id','Dividends','Stock Splits'], axis=1, inplace=True)   #At this scale, this data shouldn't matter\n",
    "    daily_df['volume_change'].interpolate(method='spline', order=3, inplace=True, limit_direction=\"both\")\n",
    "    daily_df['volume_score'].interpolate(method='spline', order=3, inplace=True, limit_direction=\"both\")\n",
    "    daily_df['bullish'].interpolate(method='spline', order=3, inplace=True, limit_direction=\"both\")\n",
    "    daily_df['bearish'].interpolate(method='spline', order=3, inplace=True, limit_direction=\"both\")\n",
    "    daily_df['Open'].interpolate(method='spline', order=3, inplace=True, limit_direction=\"both\")\n",
    "    daily_df['High'].interpolate(method='spline', order=3, inplace=True, limit_direction=\"both\")\n",
    "    daily_df['Low'].interpolate(method='spline', order=3, inplace=True, limit_direction=\"both\")\n",
    "    daily_df['Close'].interpolate(method='spline', order=3, inplace=True, limit_direction=\"both\")\n",
    "    daily_df['Volume'].interpolate(method='spline', order=3, inplace=True, limit_direction=\"both\")\n",
    "    daily_df['DayofWeek'] = daily_df['Date'].apply(lambda x: x.weekday())\n",
    "    return daily_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zackarys\\AppData\\Local\\Continuum\\anaconda3\\envs\\devenv\\lib\\site-packages\\scipy\\interpolate\\fitpack2.py:232: UserWarning: \n",
      "The maximal number of iterations maxit (set to 20 by the program)\n",
      "allowed for finding a smoothing spline with fp=s has been reached: s\n",
      "too small.\n",
      "There is an approximation returned but the corresponding weighted sum\n",
      "of squared residuals does not satisfy the condition abs(fp-s)/s < tol.\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "stock_dfs = [create_interpolated_stock_df(i) for i in stocks_to_analyze]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting ahead by 5 days\n",
    "# Choose 5% change bc it made the buys, sell, do nothing categories more balanced\n",
    "horizon_threshold = 5\n",
    "price_threshold = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine if should buy or sell or do nothing on the asset at each Open.\n",
    "def BuyorSell(df):\n",
    "    signals = []\n",
    "    df = df.sort_values(by=['Date'])\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    for index,open_value in enumerate(df['Open']):\n",
    "        high = max(list(df['High'].iloc[index : index+horizon_threshold]))\n",
    "        low =  min(list(df['Low'].iloc[index : index+horizon_threshold]))\n",
    "        \n",
    "        high_pct_diff = (high - open_value)/open_value\n",
    "        low_pct_diff = (open_value-low)/open_value\n",
    "        \n",
    "        if (high_pct_diff>low_pct_diff) and (high_pct_diff>=price_threshold):\n",
    "            signals.append(1)\n",
    "        elif (high_pct_diff<low_pct_diff) and (low_pct_diff>=price_threshold):\n",
    "            signals.append(-1)\n",
    "        else:\n",
    "            signals.append(0)\n",
    "            \n",
    "    df['Signals'] = np.array(signals)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_with_signals_list = [BuyorSell(i) for i in stock_dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I created a .py with all the indicator functions on. Here I am pulling it in. \n",
    "\n",
    "indicators = [o for o in getmembers(ind) if isfunction(o[1])]\n",
    "data = []\n",
    "for dataframe in stocks_with_signals_list:\n",
    "    for name, indicator in indicators:\n",
    "        dataframe = indicator(dataframe)\n",
    "    data.append(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "StocksWithSignalsAndIndicators = pd.concat(data, ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    3516\n",
       "-1    2563\n",
       " 0    2054\n",
       "Name: Signals, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StocksWithSignalsAndIndicators['Signals'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Even though the classes are pretty balanced, let's upsample to make them more balanced.\n",
    "# fixing imbalances classes from: https://elitedatascience.com/imbalanced-classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate majority and minority classes and a middle\n",
    "df_majority = StocksWithSignalsAndIndicators[StocksWithSignalsAndIndicators.Signals==1]\n",
    "df_minority = StocksWithSignalsAndIndicators[StocksWithSignalsAndIndicators.Signals==0]\n",
    "df_middle   = StocksWithSignalsAndIndicators[StocksWithSignalsAndIndicators.Signals==-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=len(df_majority),    # to match majority class\n",
    "                                 random_state=123) # reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample middle class\n",
    "df_middle_upsampled = resample(df_middle, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=len(df_majority),    # to match majority class\n",
    "                                 random_state=123) # reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine majority class with upsampled minority class\n",
    "StocksWithSignalsAndIndicators_upsampled = pd.concat([df_majority, df_minority_upsampled, df_middle_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    3516\n",
       " 1    3516\n",
       " 0    3516\n",
       "Name: Signals, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display new class counts\n",
    "StocksWithSignalsAndIndicators_upsampled.Signals.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "StocksWithSignalsAndIndicators_upsampled.fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data so far for later use in the classification algorithms. \n",
    "StocksWithSignalsAndIndicators_upsampled.to_csv('DataPreprocessingResults.csv')\n",
    "\n",
    "logging.info('Script has finished and csv has been created')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
